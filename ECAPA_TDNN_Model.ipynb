{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b79ee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "import os  # Provides functions to interact with the operating system\n",
    "import tkinter as tk  # Used for creating GUI applications\n",
    "from tkinter import filedialog, messagebox  # Provides file dialog boxes and pop-up messages for the GUI\n",
    "from tkinter.ttk import Progressbar  # Provides a themed progress bar widget for the GUI\n",
    "import threading  # Enables multi-threading for running tasks without freezing the GUI\n",
    "import numpy as np  # Library for handling numerical operations and working with arrays\n",
    "from tensorflow.keras.utils import to_categorical  # Converts labels into one-hot encoding for classification tasks\n",
    "import matplotlib.pyplot as plt  # Library for creating plots and visualizations\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score  # Metrics for evaluating model performance\n",
    "import seaborn as sns  # Enhances matplotlib visuals, used for creating heatmaps, etc.\n",
    "\n",
    "# Import necessary components for speech recognition tasks\n",
    "from speechbrain.inference import SpeakerRecognition  # Pre-built inference pipeline for speaker recognition tasks\n",
    "import torchaudio  # PyTorch library for audio processing\n",
    "import tensorflow as tf  # Framework for building and training machine learning models\n",
    "from tensorflow.keras import Sequential, layers  # Provides utilities for creating deep learning models\n",
    "from sklearn.model_selection import train_test_split  # Splits datasets into training and testing subsets\n",
    "from sklearn.preprocessing import LabelEncoder  # Encodes class labels as integers for model compatibility\n",
    "import tkinter as tk  # Used again to handle GUI components\n",
    "from tkinter import ttk, filedialog, messagebox, simpledialog  # Provides additional tkinter components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba5164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ECAPA-TDNN architecture as a custom Keras model\n",
    "class ECAPA_TDNN(tf.keras.Model):\n",
    "    def __init__(self, input_dim, num_classes, channels=512, bottleneck_channels=1536, embedding_dim=384):\n",
    "        super(ECAPA_TDNN, self).__init__()  # Initialize the base class\n",
    "        \n",
    "        # First TDNN layer: Applies a convolution with kernel size 5, stride 1, and 'same' padding\n",
    "        # 'relu' activation is used to introduce non-linearity\n",
    "        self.tdnn1 = layers.Conv1D(channels, kernel_size=5, strides=1, padding='same', activation='relu')\n",
    "        \n",
    "        # Second TDNN layer: Applies a convolution with kernel size 3\n",
    "        self.tdnn2 = layers.Conv1D(channels, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "        \n",
    "        # Third TDNN layer: Another convolution with kernel size 3\n",
    "        self.tdnn3 = layers.Conv1D(channels, kernel_size=3, strides=1, padding='same', activation='relu')\n",
    "        \n",
    "        # Attention mechanism: Introduces a dense layer to learn important features (tanh activation)\n",
    "        self.attention = layers.Dense(channels, activation='tanh')\n",
    "        \n",
    "        # Scaling mechanism: Outputs softmax weights to emphasize important features\n",
    "        self.scale = layers.Dense(channels, activation='softmax')\n",
    "        \n",
    "        # Fully connected layer to reduce dimensionality to the embedding size\n",
    "        self.fc1 = layers.Dense(embedding_dim, activation='relu')\n",
    "        \n",
    "        # Dropout layer for regularization to prevent overfitting\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        \n",
    "        # Final fully connected layer with softmax for classification into `num_classes`\n",
    "        self.fc2 = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    # Forward pass of the model\n",
    "    def call(self, inputs):\n",
    "        # Pass input through the first TDNN layer\n",
    "        x = self.tdnn1(inputs)\n",
    "        \n",
    "        # Pass through the second TDNN layer\n",
    "        x = self.tdnn2(x)\n",
    "        \n",
    "        # Pass through the third TDNN layer\n",
    "        x = self.tdnn3(x)\n",
    "        \n",
    "        # Apply the attention mechanism: learn attention scores for each feature\n",
    "        attn = self.attention(x)  # Dense layer for attention\n",
    "        scale = self.scale(attn)  # Convert attention scores to probabilities with softmax\n",
    "        \n",
    "        # Weighted average using the attention scores\n",
    "        x = tf.reduce_mean(x * scale, axis=1)\n",
    "        \n",
    "        # Pass through the first fully connected layer\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        # Apply dropout for regularization\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Final layer: softmax output for classification\n",
    "        output = self.fc2(x)\n",
    "        \n",
    "        return output  # Return the output of the model\n",
    "\n",
    "    # Build method to initialize weights and shapes of the model\n",
    "    def build(self, input_shape):\n",
    "        # Call the parent class's build method\n",
    "        super(ECAPA_TDNN, self).build(input_shape)\n",
    "        \n",
    "        # Build each layer with the appropriate input shapes\n",
    "        self.tdnn1.build(input_shape)  # Build the first TDNN layer\n",
    "        self.tdnn2.build(self.tdnn1.compute_output_shape(input_shape))  # Build the second TDNN layer\n",
    "        self.tdnn3.build(self.tdnn2.compute_output_shape(input_shape))  # Build the third TDNN layer\n",
    "        self.attention.build(self.tdnn3.compute_output_shape(input_shape))  # Build the attention layer\n",
    "        self.scale.build(self.tdnn3.compute_output_shape(input_shape))  # Build the scaling layer\n",
    "        self.fc1.build(self.attention.compute_output_shape(input_shape))  # Build the first fully connected layer\n",
    "        self.dropout.build(self.fc1.compute_output_shape(input_shape))  # Build the dropout layer\n",
    "        self.fc2.build(self.fc1.compute_output_shape(input_shape))  # Build the final fully connected layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f87d3",
   "metadata": {},
   "source": [
    "# Complete Code with Added Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91953f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "C:\\Users\\anasa\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
      "C:\\Users\\anasa\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "C:\\Users\\anasa\\anaconda3\\Lib\\site-packages\\speechbrain\\processing\\features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n",
      "C:\\Users\\anasa\\anaconda3\\Lib\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anasa\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\inspect_utils.py:118: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if hasattr(m, '__file__') and m.__file__ == obj_file:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 7s 55ms/step - loss: 0.5412 - accuracy: 0.8313 - val_loss: 0.0418 - val_accuracy: 0.9875\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.0459 - accuracy: 0.9859 - val_loss: 0.0243 - val_accuracy: 0.9958\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.0133 - val_accuracy: 0.9979\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0220 - val_accuracy: 0.9937\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9979\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9979\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0208 - val_accuracy: 0.9958\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 5.0683e-04 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9958\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 5.8722e-04 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9958\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 3.7653e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9958\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 6.0469e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9958\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 3.1954e-04 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9958\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 2.5505e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9979\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 1.7520e-04 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9979\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 6.7564e-04 - accuracy: 0.9995 - val_loss: 0.0216 - val_accuracy: 0.9979\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 3.4201e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9979\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 1.5610e-04 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9979\n",
      "Epoch 18/30\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 1.0709e-04 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9979\n",
      "Epoch 19/30\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 2.0009e-04 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9979\n",
      "Epoch 20/30\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 7.0370e-05 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9979\n",
      "Epoch 21/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 4.3933e-05 - accuracy: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9979\n",
      "Epoch 22/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 3.9298e-05 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9979\n",
      "Epoch 23/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 1.4964e-04 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9979\n",
      "Epoch 24/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 9.6825e-05 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9979\n",
      "Epoch 25/30\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 8.8052e-05 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9979\n",
      "Epoch 26/30\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 4.0102e-05 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9979\n",
      "Epoch 27/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 3.4753e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9979\n",
      "Epoch 28/30\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 2.6911e-05 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9979\n",
      "Epoch 29/30\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 3.6568e-05 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9979\n",
      "Epoch 30/30\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 2.6486e-05 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9979\n",
      "19/19 [==============================] - 1s 8ms/step - loss: 0.0287 - accuracy: 0.9933\n",
      "INFO:tensorflow:Assets written to: trained_ecapa_tdnn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_ecapa_tdnn_model\\assets\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
      "C:\\Users\\anasa\\anaconda3\\Lib\\site-packages\\speechbrain\\utils\\checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=device)\n",
      "C:\\Users\\anasa\\anaconda3\\Lib\\site-packages\\speechbrain\\processing\\features.py:1311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  stats = torch.load(path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 322ms/step\n"
     ]
    }
   ],
   "source": [
    "# Global variables to store data, model, and GUI elements\n",
    "directories_and_labels = []  # To store file paths and their associated labels\n",
    "all_features = []            # List to store extracted features from audio files\n",
    "all_labels = []              # List to store corresponding labels for features\n",
    "label_encoder = None         # Label encoder to encode text labels to numeric values\n",
    "ecapa_tdnn_model = None      # Placeholder for the ECAPA-TDNN model\n",
    "\n",
    "\n",
    "# GUI Initialization\n",
    "root = tk.Tk()  # Create the main window for the GUI\n",
    "root.title(\"Language Recognition GUI\")  # Set the title of the main window\n",
    "root.geometry(\"800x700\")  # Set the size of the main window (800px wide, 700px tall)\n",
    "\n",
    "\n",
    "# Create a frame to hold the file path input widgets\n",
    "frame_files = tk.Frame(root)\n",
    "frame_files.pack(pady=10)  # Add padding above and below the frame\n",
    "\n",
    "\n",
    "# Label for the entry box where the user inputs the number of file paths to load\n",
    "tk.Label(frame_files, text=\"Number of File Paths to Load\").grid(row=0, column=0, padx=5)\n",
    "\n",
    "# Entry widget for the user to input the number of file paths\n",
    "entry_num_files = tk.Entry(frame_files, width=10)  # Entry box with width set to 10 characters\n",
    "entry_num_files.grid(row=0, column=1, padx=5)  # Place the entry box in the grid layout\n",
    "\n",
    "# Button to load file paths when clicked\n",
    "btn_load_files = tk.Button(frame_files, text=\"Load File Paths\", width=15)  # Button labeled \"Load File Paths\"\n",
    "btn_load_files.grid(row=0, column=2, padx=5)  # Place the button in the grid layout\n",
    "\n",
    "# Listbox to display the loaded file paths\n",
    "listbox_files = tk.Listbox(root, width=80, height=10)  # Listbox widget with width and height specified\n",
    "listbox_files.pack(pady=10)  # Add padding above and below the Listbox\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to collect file paths and labels\n",
    "def load_file_paths():\n",
    "    try:\n",
    "        # Get the number of file paths the user wants to load from the entry widget\n",
    "        num_files = int(entry_num_files.get())  \n",
    "        \n",
    "        # Loop to allow the user to select directories and input corresponding labels\n",
    "        for i in range(num_files):\n",
    "            # Open a dialog for the user to select a directory for each file\n",
    "            file_path = filedialog.askdirectory(title=f\"Select Directory for File {i+1}\")\n",
    "            \n",
    "            # If no directory is selected, skip to the next iteration\n",
    "            if not file_path:\n",
    "                continue  \n",
    "            \n",
    "            # Open a dialog for the user to enter a label for the selected directory\n",
    "            label = simpledialog.askstring(\"Input\", f\"Enter Label for {file_path}\")\n",
    "            \n",
    "            # If a label is entered, store the directory and label pair\n",
    "            if label:\n",
    "                directories_and_labels.append((file_path, label))  # Append the pair to the list\n",
    "                \n",
    "                # Display the directory and label in the Listbox widget\n",
    "                listbox_files.insert(tk.END, f\"Path: {file_path}, Label: {label}\")  \n",
    "    except ValueError:\n",
    "        # Display an error message if the number of files entered is invalid\n",
    "        messagebox.showerror(\"Error\", \"Please enter a valid number.\")  \n",
    "\n",
    "# Configure the \"Load File Paths\" button to call the `load_file_paths` function when clicked\n",
    "btn_load_files.config(command=load_file_paths)\n",
    "\n",
    "# Progress Bar\n",
    "progress = Progressbar(root, orient=tk.HORIZONTAL, length=600, mode='determinate')  \n",
    "# Create a horizontal progress bar widget with a length of 600 pixels\n",
    "progress.pack(pady=10)  # Add padding above and below the progress bar\n",
    "\n",
    "# Text Area for Logs\n",
    "text_logs = tk.Text(root, height=10, width=80)  \n",
    "# Create a text widget to display logs with a height of 10 lines and width of 80 characters\n",
    "text_logs.pack(pady=10)  # Add padding above and below the text area\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Feature Extraction and Saving\n",
    "def start_feature_extraction():\n",
    "    global max_files_per_directory  # Declare the variable as global to modify it across functions\n",
    "\n",
    "    # Check if directories and labels have been loaded\n",
    "    if not directories_and_labels:\n",
    "        # Show an error message if no directories and labels have been loaded\n",
    "        messagebox.showerror(\"Error\", \"No directories and labels loaded.\")\n",
    "        return  # Exit the function if no data is loaded\n",
    "\n",
    "    # Prompt the user to input the maximum number of files to process from each directory\n",
    "    max_files_per_directory = simpledialog.askinteger(\n",
    "        \"Input\",  # Dialog title\n",
    "        \"Enter the maximum number of files to process from each directory (e.g., 100):\",  # Prompt message\n",
    "        parent=root  # Set the parent window for the dialog\n",
    "    )\n",
    "    \n",
    "    # Check if the user provided a valid number\n",
    "    if max_files_per_directory is None or max_files_per_directory <= 0:\n",
    "        # Show an error message if the input is invalid (None or less than or equal to 0)\n",
    "        messagebox.showerror(\"Error\", \"Please provide a valid number greater than 0.\")\n",
    "        return  # Exit the function\n",
    "\n",
    "    # Start the feature extraction process in a separate thread\n",
    "    # This prevents the GUI from freezing during the long-running task\n",
    "    threading.Thread(target=extract_and_save_features).start()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Function to extract features from audio files and save them\n",
    "def extract_and_save_features():\n",
    "    # Initialize the ECAPA-TDNN speaker recognition classifier from SpeechBrain\n",
    "    classifier = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")\n",
    "\n",
    "    # Calculate the total number of files to process across all directories\n",
    "    total_files = sum(\n",
    "        len([f for f in os.listdir(directory) if f.endswith('.mp3')][:max_files_per_directory])\n",
    "        for directory, _ in directories_and_labels\n",
    "    )\n",
    "\n",
    "    # Initialize progress tracking variables\n",
    "    processed_files = 0  # Counter for processed files\n",
    "    progress[\"maximum\"] = total_files  # Set the maximum value for the progress bar\n",
    "    progress[\"value\"] = 0  # Initialize the progress bar value to 0\n",
    "\n",
    "    # Iterate through each directory and label\n",
    "    for directory, label_name in directories_and_labels:\n",
    "        # Get a list of MP3 files in the directory, limited to the specified max files per directory\n",
    "        files = [f for f in os.listdir(directory) if f.endswith('.mp3')][:max_files_per_directory]\n",
    "        \n",
    "        # Log the processing status for the current directory and label\n",
    "        text_logs.insert(tk.END, f\"\\nProcessing directory: {directory} with label: {label_name}\")\n",
    "        root.update()  # Update the GUI to reflect the logged message\n",
    "\n",
    "        # Temporary storage for features and labels\n",
    "        temp = []\n",
    "\n",
    "        # Process each file in the directory\n",
    "        for file_name in files:\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            try:\n",
    "                # Load the audio file using torchaudio\n",
    "                signal, sample_rate = torchaudio.load(file_path)\n",
    "\n",
    "                # Resample the audio if it is not at 16 kHz\n",
    "                if sample_rate != 16000:\n",
    "                    signal = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(signal)\n",
    "\n",
    "                # Extract embeddings using the classifier\n",
    "                embeddings = classifier.encode_batch(signal).numpy()\n",
    "\n",
    "                # Append the embeddings and label to the temporary storage\n",
    "                temp.append([embeddings, label_name])\n",
    "            except Exception as e:\n",
    "                # Log any errors encountered while processing the file\n",
    "                text_logs.insert(tk.END, f\"\\nError processing {file_name}: {e}\")\n",
    "                root.update()  # Update the GUI to reflect the logged error message\n",
    "\n",
    "            # Update the progress bar and GUI\n",
    "            processed_files += 1\n",
    "            progress[\"value\"] = processed_files\n",
    "            root.update()\n",
    "\n",
    "        # Separate features and labels from the temporary storage\n",
    "        features = [item[0] for item in temp]\n",
    "        labels = [item[1] for item in temp]\n",
    "\n",
    "        # Save features and labels to NumPy files for the current label\n",
    "        np.save(f\"ecapa_train_features_{label_name}.npy\", np.array(features, dtype=object))\n",
    "        np.save(f\"ecapa_train_labels_{label_name}.npy\", np.array(labels))\n",
    "\n",
    "        # Log that features and labels have been saved\n",
    "        text_logs.insert(tk.END, f\"\\nFeatures and labels saved for {label_name}.\")\n",
    "        root.update()  # Update the GUI to reflect the logged message\n",
    "\n",
    "    # Show a message box when feature extraction for all directories is complete\n",
    "    messagebox.showinfo(\"Feature Extraction Complete\", \"Feature extraction for all languages is complete!\")\n",
    "\n",
    "# Create a button to trigger feature extraction\n",
    "btn_extract_features = tk.Button(root, text=\"Extract Features\", command=start_feature_extraction)\n",
    "btn_extract_features.pack(pady=10)  # Add padding to separate it from other GUI elements\n",
    "\n",
    "# Frame for language count input\n",
    "frame_languages = tk.Frame(root)  # Create a frame for organizing the language count input\n",
    "frame_languages.pack(pady=10)  # Add padding to the frame\n",
    "\n",
    "# Add a label to prompt the user for the number of languages to train on\n",
    "tk.Label(frame_languages, text=\"Enter Number of Languages to Train On\").grid(row=0, column=0, padx=5)\n",
    "\n",
    "# Add an entry field for the user to input the number of languages\n",
    "entry_num_languages = tk.Entry(frame_languages, width=10)\n",
    "entry_num_languages.grid(row=0, column=1, padx=5)\n",
    "\n",
    "# Add a button to confirm the number of languages entered\n",
    "btn_confirm_languages = tk.Button(frame_languages, text=\"Confirm\", width=10)\n",
    "btn_confirm_languages.grid(row=0, column=2, padx=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Train and Evaluate Model with Accuracy Display\n",
    "def train_and_evaluate_model():\n",
    "    global all_features, all_labels\n",
    "\n",
    "    try:\n",
    "        # Get the number of languages to train on from the user\n",
    "        num_languages = int(entry_num_languages.get())\n",
    "\n",
    "        # Initialize lists to store paths to feature and label files\n",
    "        feature_paths = []\n",
    "        label_paths = []\n",
    "\n",
    "        # Collect feature and label files for each language\n",
    "        for i in range(num_languages):\n",
    "            # Ask the user to select the feature file for the current language\n",
    "            feature_file = filedialog.askopenfilename(\n",
    "                title=f\"Select Feature File for Language {i + 1}\",\n",
    "                filetypes=((\"NumPy Files\", \"*.npy\"),),\n",
    "            )\n",
    "            if not feature_file:\n",
    "                # Show an error if the feature file is not provided\n",
    "                messagebox.showerror(\"Error\", f\"Feature file for Language {i + 1} is required.\")\n",
    "                return\n",
    "\n",
    "            # Ask the user to select the label file for the current language\n",
    "            label_file = filedialog.askopenfilename(\n",
    "                title=f\"Select Label File for Language {i + 1}\",\n",
    "                filetypes=((\"NumPy Files\", \"*.npy\"),),\n",
    "            )\n",
    "            if not label_file:\n",
    "                # Show an error if the label file is not provided\n",
    "                messagebox.showerror(\"Error\", f\"Label file for Language {i + 1} is required.\")\n",
    "                return\n",
    "\n",
    "            # Append the selected feature and label file paths to their respective lists\n",
    "            feature_paths.append(feature_file)\n",
    "            label_paths.append(label_file)\n",
    "\n",
    "        # Load features and labels from the selected files\n",
    "        for feature_path, label_path in zip(feature_paths, label_paths):\n",
    "            features = np.load(feature_path, allow_pickle=True).astype(np.float32)  # Load features\n",
    "            labels = np.load(label_path, allow_pickle=True)  # Load labels\n",
    "            all_features.append(features)  # Add to global features list\n",
    "            all_labels.append(labels)  # Add to global labels list\n",
    "\n",
    "        # Prepare combined data by concatenating features and labels across all languages\n",
    "        all_features_combined = np.concatenate(all_features, axis=0)\n",
    "        all_labels_combined = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "        # Encode labels into numerical format using LabelEncoder\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(all_labels_combined)\n",
    "\n",
    "        # Split data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(all_features_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Convert labels to one-hot encoding for training\n",
    "        y_train_one_hot = to_categorical(y_train)\n",
    "        y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "        # Reshape the features to match ECAPA-TDNN input requirements (1 time step, 192 features)\n",
    "        X_train = X_train.reshape(-1, 1, 192)\n",
    "        X_test = X_test.reshape(-1, 1, 192)\n",
    "\n",
    "        # Define the ECAPA-TDNN model\n",
    "        input_shape = (1, 192)  # Shape of the input (1 time step, 192 features)\n",
    "        num_classes = len(label_encoder.classes_)  # Number of language classes\n",
    "\n",
    "        # Initialize the ECAPA-TDNN model with the defined input shape and number of classes\n",
    "        ecapa_tdnn_model = ECAPA_TDNN(input_shape, num_classes)\n",
    "        ecapa_tdnn_model.build(input_shape=(None, input_shape[0], input_shape[1]))\n",
    "\n",
    "        # Compile the model with AdamW optimizer and categorical crossentropy loss\n",
    "        optimizer = tf.keras.optimizers.AdamW(learning_rate=0.0001)\n",
    "        ecapa_tdnn_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        # Train the model using the training data, with validation split of 20%\n",
    "        history = ecapa_tdnn_model.fit(\n",
    "            X_train, y_train_one_hot,\n",
    "            epochs=30,  # Number of epochs for training\n",
    "            batch_size=32,  # Batch size for training\n",
    "            validation_split=0.2  # Use 20% of training data for validation\n",
    "        )\n",
    "\n",
    "        # Evaluate the trained model on the testing data\n",
    "        test_loss, test_accuracy = ecapa_tdnn_model.evaluate(X_test, y_test_one_hot)\n",
    "\n",
    "        # Save the trained model and label encoder\n",
    "        ecapa_tdnn_model.save(\"trained_ecapa_tdnn_model\", save_format=\"tf\")  # Save the model in TensorFlow format\n",
    "        np.save(\"trained_label_encoder.npy\", label_encoder.classes_)  # Save the label encoder classes\n",
    "\n",
    "        # Retrieve training and validation accuracy from the training history\n",
    "        training_accuracy = history.history['accuracy'][-1]  # Last epoch training accuracy\n",
    "        validation_accuracy = history.history['val_accuracy'][-1]  # Last epoch validation accuracy\n",
    "\n",
    "        # Display a message box with training, validation, and test accuracy\n",
    "        messagebox.showinfo(\n",
    "            \"Training Complete\",\n",
    "            f\"Model training complete!\\n\\n\"\n",
    "            f\"Training Accuracy: {training_accuracy:.4f}\\n\"\n",
    "            f\"Validation Accuracy: {validation_accuracy:.4f}\\n\"\n",
    "            f\"Test Accuracy: {test_accuracy:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Log accuracy details in the text_logs area\n",
    "        text_logs.insert(\n",
    "            tk.END,\n",
    "            f\"\\nTraining Accuracy: {training_accuracy:.4f}\\n\"\n",
    "            f\"Validation Accuracy: {validation_accuracy:.4f}\\n\"\n",
    "            f\"Test Accuracy: {test_accuracy:.4f}\\n\"\n",
    "        )\n",
    "        root.update()  # Update the GUI to reflect the logged details\n",
    "\n",
    "    except Exception as e:\n",
    "        # Show an error message if any exception occurs\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "\n",
    "# Button to start the training and evaluation process\n",
    "btn_train_model = tk.Button(root, text=\"Train and Save Model\", command=train_and_evaluate_model)\n",
    "btn_train_model.pack(pady=10)  # Add padding for better UI spacing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to load the trained model and make predictions\n",
    "def load_model_and_predict():\n",
    "    try:\n",
    "        # Ask the user to select the trained model directory\n",
    "        model_path = filedialog.askdirectory(title=\"Select Trained Model Directory\")\n",
    "        if not model_path:  # If no directory is selected, show an error message\n",
    "            messagebox.showerror(\"Error\", \"Model directory is required.\")\n",
    "            return\n",
    "\n",
    "        # Ask the user to select the label encoder file\n",
    "        label_encoder_path = filedialog.askopenfilename(\n",
    "            title=\"Select Label Encoder File\", filetypes=((\"NumPy Files\", \"*.npy\"),)\n",
    "        )\n",
    "        if not label_encoder_path:  # If no file is selected, show an error message\n",
    "            messagebox.showerror(\"Error\", \"Label encoder file is required.\")\n",
    "            return\n",
    "\n",
    "        # Load the trained model and label encoder\n",
    "        global ecapa_tdnn_model, label_encoder\n",
    "        ecapa_tdnn_model = tf.keras.models.load_model(model_path)  # Load the trained model\n",
    "        label_encoder_classes = np.load(label_encoder_path, allow_pickle=True)  # Load the label encoder classes\n",
    "        label_encoder = LabelEncoder()  # Create a new label encoder\n",
    "        label_encoder.classes_ = label_encoder_classes  # Assign loaded classes to the label encoder\n",
    "\n",
    "        # Ask the user to select the MP3 file for prediction\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select an MP3 File for Prediction\", filetypes=((\"MP3 Files\", \"*.mp3\"),)\n",
    "        )\n",
    "        if not file_path:  # If no file is selected, show an error message\n",
    "            messagebox.showerror(\"Error\", \"MP3 file is required.\")\n",
    "            return\n",
    "\n",
    "        # Extract features from the selected MP3 file using the ECAPA-TDNN encoder\n",
    "        classifier = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-ecapa-voxceleb\")  # Load the pre-trained classifier\n",
    "        signal, sample_rate = torchaudio.load(file_path)  # Load the MP3 file into signal and sample rate\n",
    "        if sample_rate != 16000:  # Resample the audio if the sample rate is not 16kHz\n",
    "            signal = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(signal)\n",
    "        embeddings = classifier.encode_batch(signal).numpy()  # Generate embeddings for the audio file\n",
    "        embeddings = embeddings.reshape(1, 1, 192)  # Reshape the embeddings to match model input shape\n",
    "\n",
    "        # Use the loaded model to predict the language\n",
    "        predictions = ecapa_tdnn_model.predict(embeddings)  # Get softmax probabilities for each class\n",
    "        predicted_index = np.argmax(predictions)  # Find the index of the class with the highest probability\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_index])[0]  # Map the index to the corresponding label\n",
    "\n",
    "        # Generate confidence scores for all language labels\n",
    "        confidence_scores = predictions[0]  # Extract the probabilities (softmax values) for each label\n",
    "        confidence_info = \"\\n\".join(\n",
    "            [f\"{label}: {confidence * 100:.2f}%\" for label, confidence in zip(label_encoder.classes_, confidence_scores)]\n",
    "        )\n",
    "\n",
    "        # Show a message box with the predicted label and confidence scores for all labels\n",
    "        messagebox.showinfo(\n",
    "            \"Prediction Complete\",\n",
    "            f\"Predicted Language: {predicted_label}\\n\\n\"\n",
    "            f\"Confidence for each label:\\n{confidence_info}\\n\\n\"\n",
    "            f\"Trained Language Labels: {list(label_encoder.classes_)}\"\n",
    "        )\n",
    "\n",
    "    except Exception as e:  # Handle exceptions during prediction\n",
    "        messagebox.showerror(\"Error\", f\"An error occurred: {e}\")\n",
    "\n",
    "# Create a button to trigger the prediction process\n",
    "btn_predict_model = tk.Button(root, text=\"Load Model and Predict\", command=load_model_and_predict)\n",
    "btn_predict_model.pack(pady=10)  # Add padding around the button for better spacing\n",
    "\n",
    "# Start the Tkinter main loop to run the GUI application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5f538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
